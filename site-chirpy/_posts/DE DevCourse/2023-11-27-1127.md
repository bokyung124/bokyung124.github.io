---
title: "[DEV] 8주차. 데이터 웨어하우스 관리와 고급 SQL과 BI 대시보드(1)"
last_modified_at: 2023-11-27T12:00:00-05:00
layout: post
categories:
    - Data Engineering
excerpt: 
toc: true
toc_sticky: true
toc_icon: "cog"
author_profile: true
mathjax: true
tag: [DevCourse, TIL, DE, KDT, DW]
---

## 1. 데이터 웨어하우스

- 기본적으로 클라우드가 대세
- 데이터가 커져도 문제없는 확장가능성(scalable)과 적절한 비용이 중요 포인트
- 크게 **고정비용 옵션**과 **가변비용 옵션**이 존재하며, 후자가 조금 더 확장 가능한 옵션
- AWS Redshift, 구글 BigQuery, Snowflake
    - Redshift는 고정비용, BigQuery와 Snowflake는 가변비용
- 오픈 소스 기반(Presto, Hive)을 사용하는 경우도 클라우드 버전 존재
- 데이터가 작다면 굳이 빅데이터 기반 데이터베이스를 사용할 필요가 없음

## 2. 데이터 레이크

- 구조화 데이터 + 비구조화 데이터 (로그 파일)
- 보존 기한이 없는 모든 데이터를 원래 형태대로 보존하는 **스토리지**에 가까움
- 보통은 데이터 웨어하우스보다 몇 배는 더 크고 경제적인 스토리지
- 보통 클라우드 스토리지가 됨
    - 대표적으로 AWS S3가 있음
- 데이터 레이크가 있는 환경에서 ETL과 ELT
    - ETL: 데이터 레이크와 데이터 웨어하우스 밖에서 안으로 데이터를 가져오는 것
    - ELT: 데이터 레이크와 데이터 웨어하우스 안에 있는 데이터를 처리하는 것
- LOG -> [Data Lake -> Data Warehouse]

## 3. 다양한 데이터 소스 예

- 프로덕션 데이터베이스의 데이터 
    - 보통 MySQL, PostgreSQL 등이 프로덕션 데이터베이스로 사용됨
- 이메일 마케팅 데이터
    - Mailchimp, HubSpot, SendGrid
- 크레딧카드 매출 데이터
    - Stripe
- 서포트 티켓 데이터
    - Zendesk, Kustomer
- 서포트 콜 데이터
    - ChannelTalk, RingCentral, Talkdesk
- 세일즈 데이터
    - Salesforce
- 사용자 이벤트 로그
    - Amplitude, MixPanel, 웹서버 로그

## 4. Airflow

- **ETL 관리 및 운영 프레임워크의 필요성**
    - 다수의 ETL이 존재할 경우, 이를 스케줄링 해주고 이들 간의 의존관계(dependency)를 정의해주는 기능 필요
    - 특정 ETL이 실패할 경우 이에 관한 에러 메시지를 받고 재실행해주는 기능도 중요해짐 (Backfill)

- 가장 많이 사용되는 프레임워크는 **Airflow**
    - 오픈소스 프로젝트로 파이썬3 기반
        - AWS, Google Cloud, Azure에서도 지원함
    - Airflow 에서는 ETL을 **DAG**라고 부르며 웹 인터페이스를 통한 관리 기능 제공
    - 크게 스케줄러, 웹서버, 워커로 구성

## 5. ELT

- **ETL**
    - 데이터를 데이터 웨어하우스 외부에서 내부로 가져오는 프로세스
    - 보통 데이터 엔지니어가 이를 수행함

- **ELT**
    - 데이터 웨어하우스 내부 데이터를 조작해서 새로운 데이터를 만드는 프로세스
    - 이런 프로세스 전용 기술들이 있으며 **dbt**가 가장 유명함
    - 보통 데이터 분석가가 이를 수행함
    - 이 경우 데이터 레이크를 사용하기도 함

## 6. 데이터 웨어하우스 옵션들

- Iceberg을 제외하고는 모두 **SQL**을 지원하는 **빅데이터** 기반 데이터베이스 (데이터 처리 엔진)
- Iceberg는 스토리지에 가까움

### AWS Redshift

- AWS 기반의 데이터 웨어하우스로, PB 스케일 데이터 분산 처리 가능 (최대 2PB)
    - PostgreSQL과 호환되는 SQL로 처리 가능
    - Python UDF 작성으로 기능 확장 가능
    - 처음에는 고정비용 모델로 시작했으나, 이제는 가변비용 모델도 지원 (Redshift Serverless)
    - 온디맨드 가격 이외에도 예약 가격 옵션도 지원

- CSV, JSON, Avro, Parquet 등과 같은 다양한 데이터 포맷 지원
- AWS 내의 다른 서비스들과 연동이 쉬움
    - S3, DynamoDB, SageMaker 등
    - ML 모델의 실행도 지원 (SageMaker)
    - Redshift의 기능 확장을 위해 Redshift Spectrum, AWS Athena 등의 서비스와 같이 이용 가능
- 배치 데이터 중심이지만 실시간 데이터 처리도 지원
- 웹 콘솔 이외에도 API를 통한 관리/제어 가능


### Snowflake

- 클라우드 기반 데이터 웨어하우스로 시작됨
    - 지금은 데이터 클라우드라고 부를 수 있을 정도로 발전
    - 데이터 판매를 통한 매출을 가능하게 해주는 Data Sharing / Marketplace 제공
    - ETL과 다양한 데이터 통합 기능 제공

- SQL 기반으로 빅데이터 저장, 처리, 분석을 가능하게 해줌
    - Python UDF로 비구조화된 데이터 처리와 머신러닝 기능 제공
- CSV, JSON, Avro, Parquet 등과 같은 다양한 데이터 포맷 지원
    - S3, GC 클라우드 스토리지, Azure Blog Storage도 지원
- 배치 데이터 중심이지만 실시간 데이터 처리도 지원
- 웹 콘솔 이외에도 API를 통한 관리/제어 가능


### Google Cloud BigQuery

- 구글 클라우드의 데이터 웨어하우스 서비스
    - BigQuery SQL로 데이터 처리 가능 (Nested fields, repeated fields 지원 -> 복잡한 형태 처리 가능) 
        - `nested fileds`: JSON처럼 sub fields가 있는 형태
        - `repeated fields`: list array
    - 가변 비용과 고정 비용 옵션 지원
        - 기본은 가변 비용 옵션 -> DW의 스토리지와 컴퓨팅 부분이 분리 -> 컴퓨팅을 업그레이드하기 위해 스토리지를 업그레이드 할 필요가 없음 -> scalable
        
- CSV, JSON, Avro, Parquet 등과 같은 다양한 데이터 포맷 지원
- 구글 클라우드 내의 다른 서비스들과 연동이 쉬움
    - 클라우드 스토리지, 데이터플로우, AutoML 등 
- 배치 데이터 중심이지만 실시간 데이터 처리도 지원
- 웹 콘솔 이외에도 API를 통한 관리/제어 가능

### Apache Hive

- Facebook이 2008년에 시작한 아파치 오픈소스 프로젝트
- 하둡 기반으로 동작하는 SQL 기반 데이터 웨어하우스 서비스
    - HiveQL 지원
    - MapReduce 위에서 동작하는 버전과, Apache Tez를 실행 엔진으로 동작하는 버전 두 가지가 존재
    - 다른 하둡 기반 오픈소스들과 연동이 쉬움 (Spark, HBase 등)
    - JAVA나 Python으로 UDF 작성 가능

- CSV, JSON, Avro, Parquet 등과 같은 다양한 데이터 포맷 지원
- 배치 빅데이터 프로세싱 시스템
    - 데이터 파티셔닝과 버킷팅과 같은 최적화 작업 지원
    - 빠른 처리 속도보다는 처리할 수 있는 데이터 양의 크기에 최적화
- 웹 UI와 커맨드라인 UI (CLI) 지원
- 점점 Spark에 의해 밀리는 분위기


### Apache Presto

- Facebook이 2008년에 시작한 아파치 오픈소스 프로젝트
- 다양한 데이터소스에 존재하는 데이터를 대상으로 SQL 실행 가능
    - HDFS, S3, Cassandra, MySQL 등
    - PrestoSQL 지원

- CSV, JSON, Avro, ORC, Parquet 등과 같은 다양한 데이터 포맷 지원
- 배치 빅데이터 프로세싱 시스템
    - Hive와는 다르게 빠른 응답 속도에 조금 더 최적화 (메모리 기반)
- 웹 UI와 커맨드라인 UI (CLI) 지원
- AWS Athena가 Presto를 기반으로 만들어진 것


### Apache Iceberg (data lake)

- Netflix가 시작한 아파치 오픈소스 프로젝트로, 데이터 웨어하우스 기술이 아님!
- 대용량 SCD (Slowly-Changing Datasets) 데이터를 다룰 수 있는 테이블 포맷
    - HDFS, S3, Azure Blob Storage 등의 클라우드 스토리지 지원
    - ACID 트랜잭션과 Time Travel (과거 버전으로 롤백과 변경 기록 유지 등)
        - `ACID` : 원자성, 일관성, 신뢰성, 격리성, 영속성
    - Schema Evolution 지원을 통한 컬럼 제거와 추가 가능 (테이블 재작성 없이)
        - 특정 파일의 포맷이 어떻게 변화해 왔는지 트랙킹 가능

- JAVA와 Python API 지원
- Spark, Flink, Hive, Hudi 등의 다른 아파치 시스템과 연동 가능
    - Iceberg와 Spark를 함께 사용하는 사례가 많음 (실리콘밸리)

### Apache Spark (bigdata processing)

- UC 버클리 AMPLab이 2013년에 시작한 아파치 오픈소스 프로젝트
    - Python의 Pandas처럼 빅데이터 처리를 하게 하자는 목표로 시작
    - 기본적으로 데이터 처리를 DataFrame API를 사용 + 이외에도 SQL 기능 가능하도록 + 실시간 처리 연동
- 빅데이터 처리 관련 종합선물세트 
    - 배치처리 (API/SQL), 실시간 처리, 그래프 처리, 머신러닝 기능 제공
- 다양한 분산처리 시스템 지원
    - 하둡 (Yarn), AWS EMR, Google Cloud Dataproc, Mesos, K8s 등
- 다양한 파일시스템과 연동 가능
    - HDFS, S3, Cassandra, HBase emd
- CSV, JSON, Avro, ORC, Parquet 등과 같은 다양한 데이터 포맷 지원
- 다양한 언어 지원: JAVA, Python, Scala, R


## 7. 실리콘밸리 회사들의 데이터 스택 트렌드

### 데이터 플랫폼의 발전 단계

- **초기 단계: 데이터 웨어하우스 + ETL**

- **발전 단계: 데이터 양 증가**
    - Spark와 같은 빅데이터 처리시스템 도입
    - 데이터 레이크 도입

- **성숙 단계: 데이터 활용 증대**
    - 현업단의 데이터 활용이 가속화
    - ELT 단이 더 중요해지면서 dbt 등의 analytics engineering 도입
        - ELT 작성이 더 쉬워져야 함, 데이터 품질이 보장되어야 함
    - MLOps 등 머신러닝 관련 효율성 증대 노력 증대

### 발전 단계: 데이터 양 증가

- Spark와 같은 빅데이터 처리시스템 도입
- **데이터 레이크** 도입: 보통 로그 데이터와 같은 대용량 비구조화 데이터 대상
    - 데이터 소스 -> 데이터 파이프라인 -> 데이터 웨어하우스
    - 데이터 소스 -> 데이터 파이프라인 -> 데이터 레이크
    - 데이터 레이크 -> 데이터 파이프라인 -> 데이터 웨어하우스
        - 이때 Spark/Hadoop 등이 사용됨 (데이터 레이크는 대용량이기 때문)
        - Hadoop: Hive/Presto 등이 기반됨

### 성숙 단계: 현업단의 데이터 활용 가속화

- ELT 단이 더 중요해지면서 **dbt** 등의 analytics engineering 도입
    - ELT: 데이터 레이크 to 데이터 레이크, 데이터 레이크 to 데이터 웨어하우스, 데이터 웨어하우스 to 데이터 웨어하우스
- MLOps 등 머신러닝 개발 운영 관련 효율성 증대 노력 증대


### 실리콘밸리 회사 데이터 스택 비교

<img width="1409" alt="스크린샷 2023-12-01 오후 4 08 10" src="https://github.com/bokyung124/Algorithm_Exercise/assets/53086873/cf9992e6-95a9-49f2-8533-81e6c52d398f">